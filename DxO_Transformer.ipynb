{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DxO Transformer",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMSU7Sinnj1KvwMjpEaSN9J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-ak/t2/blob/master/DxO_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AowKVp_jG8fi",
        "colab_type": "text"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZEkI8YwG5q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "#import feather\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "#import keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "#from keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, TimeDistributed\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('\\n\\n\\nYour runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, Runtime > \"Change runtime type\"')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!\\n\\n')\n",
        "\n",
        "print(tf.__version__) # 2.2.0\n",
        "print(keras.__version__) # 2.3.1 (tf imports 2.3.0-tf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6zT-EJky4Y9",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMB1qbWy9BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('https://davidak.s3-us-west-1.amazonaws.com/SID+SEDD/Data+main/nat_CA_60k.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EbTRuVSzS6Y",
        "colab_type": "text"
      },
      "source": [
        "# Format data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t45lHoM5zUX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data.shape) # 604,034 rows, 115 columns\n",
        "print('{:.0f} unique IDs'.format(len(pd.unique(data['ID2'])))) # 60,000 unique IDs\n",
        "data.sort_values(by=['ID2', 'Visit_no'], ascending=[True, False], inplace=True) # Sort by ID2, -Visit_no\n",
        "# data['Interval'] = (np.log(math.e + data.Interval))**-1 # Format interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzisLO06zci0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sPazS-czhvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_EC_CCS = [str('CCS_EC_'+str(i)) for i in ['prin',*range(1,5)]]\n",
        "cols_Dx_CCS = [str('CCS_Dx_'+str(i)) for i in ['prin',*range(1,25)]]\n",
        "cols_Proc_CCS = [str('CCS_Proc_'+str(i)) for i in ['prin',*range(1,21)]]\n",
        "from itertools import chain\n",
        "cols_all = list(chain.from_iterable([['Interval','Type','Age','Sex','Race','Payer','Pt_zip_inc_qrtl','Dispo'],cols_EC_CCS,cols_Dx_CCS,cols_Proc_CCS]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD2ZX9dprbYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u93Ls5gM0h09",
        "colab_type": "text"
      },
      "source": [
        "## Bin age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHRI-SuZ-zKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Age'] = data.Age.astype('int')\n",
        "data['Age'] = pd.cut(data['Age'], bins=np.linspace(0,130,14))\n",
        "data['Age'] = data.Age.astype(str)\n",
        "data['Age'] = data.Age.apply(lambda x:x.replace('.0',''))\n",
        "data['Age'] = data.Age.apply(lambda x:x.replace(', ','_'))\n",
        "data['Age'] = data.Age.apply(lambda x:x.replace(']',''))\n",
        "data['Age'] = data.Age.apply(lambda x:x.replace('(',''))\n",
        "pd.value_counts(data.Age)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naAmz_6uaGrr",
        "colab_type": "text"
      },
      "source": [
        "## Bin interval -- use the same bins on other states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAaU1Q_HaIYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Interval'] = pd.qcut(data['Interval'],q=10).astype(str)\n",
        "data['Interval'] = data.Interval.apply(lambda x:x.replace('-001','0'))\n",
        "data['Interval'] = data.Interval.astype(str)\n",
        "data['Interval'] = data.Interval.apply(lambda x:x.replace('.0',''))\n",
        "data['Interval'] = data.Interval.apply(lambda x:x.replace(', ','_'))\n",
        "data['Interval'] = data.Interval.apply(lambda x:x.replace(']',''))\n",
        "data['Interval'] = data.Interval.apply(lambda x:x.replace('(',''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuADNSohv2Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.value_counts(data.Interval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFBLLFFLCC0h",
        "colab_type": "text"
      },
      "source": [
        "## Append var names to all fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ofi7BeK_VGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.Interval = 'Interval_'+data.Interval\n",
        "data.Type = 'Type_'+data.Type\n",
        "data.Age = 'Age_'+data.Age.astype('str')\n",
        "data.Sex = 'Sex_'+data.Sex\n",
        "data.Race = 'Race_'+data.Race\n",
        "data.Payer = 'Payer_'+data.Payer\n",
        "data.Pt_zip_inc_qrtl = np.nan_to_num(data.Pt_zip_inc_qrtl,nan=0)\n",
        "data.Pt_zip_inc_qrtl = data.Pt_zip_inc_qrtl.astype('int').astype('str')\n",
        "data.Pt_zip_inc_qrtl = 'Pt_zip_inc_qrtl_'+data.Pt_zip_inc_qrtl\n",
        "data.Dispo = 'Dispo_'+data.Dispo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P46LL4vOJLOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in cols_EC_CCS:\n",
        "  data.loc[:,i] = np.nan_to_num(data.loc[:,i],nan=0)\n",
        "  data.loc[:,i] = 'CCS_EC_'+data.loc[:,i].astype('int').astype('str')\n",
        "  data.loc[:,i] = data[i].replace('CCS_EC_0',np.NaN)\n",
        "\n",
        "for i in cols_Dx_CCS:\n",
        "  data.loc[:,i] = np.nan_to_num(data.loc[:,i],nan=0)\n",
        "  data.loc[:,i] = 'CCS_Dx_'+data.loc[:,i].astype('int').astype('str')\n",
        "  data.loc[:,i] = data[i].replace('CCS_Dx_0',np.NaN)\n",
        "\n",
        "for i in cols_Proc_CCS:\n",
        "  data.loc[:,i] = np.nan_to_num(data.loc[:,i],nan=0)\n",
        "  data.loc[:,i] = 'CCS_Proc_'+data.loc[:,i].astype('int').astype('str')\n",
        "  data.loc[:,i] = data[i].replace('CCS_Proc_0',np.NaN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql4tpih9Eaa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[0:10,list(chain.from_iterable([cols_EC_CCS,cols_Dx_CCS,cols_Proc_CCS]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PFgtt6P6CmB",
        "colab_type": "text"
      },
      "source": [
        "## Make lists of tokenized fields (tokenized) for each visit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S03xsiJFOL2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[:,cols_all].shape # (604034, 59)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noNbdnmphU1F",
        "colab_type": "text"
      },
      "source": [
        "### Split X/y/ID2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6PcmA_WRAwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.loc[:,'Case'].to_numpy().flatten()\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEeGK3qlX-Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID2 = data.loc[:,'ID2'].to_numpy().flatten()\n",
        "print(ID2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE0Fq1ezOXXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.loc[:,cols_all] # leave case in here?"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dswNiV96OalU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields_unique = pd.unique(X.loc[:,cols_all].values.ravel('K'))\n",
        "fields_unique = fields_unique.astype(str)\n",
        "fields_unique.sort\n",
        "fields_unique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "truO6EoSQFHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matching = [s for s in fields_unique if any(xs in s for xs in ['nan'])]\n",
        "matching # ['Interval_nan', 'Age_nan', 'nan']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSJphH3UQ7RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields_unique = [x for x in fields_unique if x not in matching]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuPOR-aChZms",
        "colab_type": "text"
      },
      "source": [
        "### Dict field <> token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSsRnzH0SWDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_dict = dict(zip(list(fields_unique), list(range(len(fields_unique)))))"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng024BM8i_pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in cols_all:\n",
        "  X[i] = X[i].map(my_dict).astype('float32')\n",
        "  #print(i)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh3muM7liT5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ee602f45-539f-43f0-83e3-1614793fb71c"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Interval</th>\n",
              "      <th>Type</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Race</th>\n",
              "      <th>Payer</th>\n",
              "      <th>Pt_zip_inc_qrtl</th>\n",
              "      <th>Dispo</th>\n",
              "      <th>CCS_EC_prin</th>\n",
              "      <th>CCS_EC_1</th>\n",
              "      <th>CCS_EC_2</th>\n",
              "      <th>CCS_EC_3</th>\n",
              "      <th>CCS_EC_4</th>\n",
              "      <th>CCS_Dx_prin</th>\n",
              "      <th>CCS_Dx_1</th>\n",
              "      <th>CCS_Dx_2</th>\n",
              "      <th>CCS_Dx_3</th>\n",
              "      <th>CCS_Dx_4</th>\n",
              "      <th>CCS_Dx_5</th>\n",
              "      <th>CCS_Dx_6</th>\n",
              "      <th>CCS_Dx_7</th>\n",
              "      <th>CCS_Dx_8</th>\n",
              "      <th>CCS_Dx_9</th>\n",
              "      <th>CCS_Dx_10</th>\n",
              "      <th>CCS_Dx_11</th>\n",
              "      <th>CCS_Dx_12</th>\n",
              "      <th>CCS_Dx_13</th>\n",
              "      <th>CCS_Dx_14</th>\n",
              "      <th>CCS_Dx_15</th>\n",
              "      <th>CCS_Dx_16</th>\n",
              "      <th>CCS_Dx_17</th>\n",
              "      <th>CCS_Dx_18</th>\n",
              "      <th>CCS_Dx_19</th>\n",
              "      <th>CCS_Dx_20</th>\n",
              "      <th>CCS_Dx_21</th>\n",
              "      <th>CCS_Dx_22</th>\n",
              "      <th>CCS_Dx_23</th>\n",
              "      <th>CCS_Dx_24</th>\n",
              "      <th>CCS_Proc_prin</th>\n",
              "      <th>CCS_Proc_1</th>\n",
              "      <th>CCS_Proc_2</th>\n",
              "      <th>CCS_Proc_3</th>\n",
              "      <th>CCS_Proc_4</th>\n",
              "      <th>CCS_Proc_5</th>\n",
              "      <th>CCS_Proc_6</th>\n",
              "      <th>CCS_Proc_7</th>\n",
              "      <th>CCS_Proc_8</th>\n",
              "      <th>CCS_Proc_9</th>\n",
              "      <th>CCS_Proc_10</th>\n",
              "      <th>CCS_Proc_11</th>\n",
              "      <th>CCS_Proc_12</th>\n",
              "      <th>CCS_Proc_13</th>\n",
              "      <th>CCS_Proc_14</th>\n",
              "      <th>CCS_Proc_15</th>\n",
              "      <th>CCS_Proc_16</th>\n",
              "      <th>CCS_Proc_17</th>\n",
              "      <th>CCS_Proc_18</th>\n",
              "      <th>CCS_Proc_19</th>\n",
              "      <th>CCS_Proc_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>84.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>347.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>348.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>347.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>380.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Interval  Type   Age  ...  CCS_Proc_18  CCS_Proc_19  CCS_Proc_20\n",
              "0       0.0  10.0  12.0  ...          NaN          NaN          NaN\n",
              "1       1.0  10.0  13.0  ...          NaN          NaN          NaN\n",
              "2       1.0  11.0  13.0  ...          NaN          NaN          NaN\n",
              "3       2.0  11.0  13.0  ...          NaN          NaN          NaN\n",
              "4       3.0  11.0  13.0  ...          NaN          NaN          NaN\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do1pjLhMB-bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 59 # num cols -c(ID2,Case,Visit_no,Adm_LOS,Adm_charges)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0LAF8oObH3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6eaa1d53-1ae8-4727-c19c-191b73b2c89f"
      },
      "source": [
        "X = X.to_numpy()\n",
        "print(X)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. 10. 12. ... nan nan nan]\n",
            " [ 1. 10. 13. ... nan nan nan]\n",
            " [ 1. 11. 13. ... nan nan nan]\n",
            " ...\n",
            " [ 7. 11. 21. ... nan nan nan]\n",
            " [ 7. 11. 21. ... nan nan nan]\n",
            " [nan 11. 21. ... nan nan nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBJbloNsgfjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean = [[i for i in row if str(i) != 'nan'] for row in X]\n",
        "clean = np.asarray(clean, dtype=object)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xbjSHWAlWy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "82f29a87-f97f-46de-98b8-8349e134310c"
      },
      "source": [
        "clean"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([0.0, 10.0, 12.0, 23.0, 26.0, 33.0, 38.0, 43.0, 84.0, 89.0, 158.0, 164.0, 112.0, 184.0, 239.0, 93.0, 347.0]),\n",
              "       list([1.0, 10.0, 13.0, 23.0, 26.0, 33.0, 38.0, 44.0, 85.0, 144.0, 158.0, 89.0, 201.0, 307.0, 184.0, 223.0, 112.0, 100.0, 239.0, 116.0, 348.0, 555.0, 387.0, 347.0, 417.0, 380.0, 383.0]),\n",
              "       list([1.0, 11.0, 13.0, 23.0, 26.0, 33.0, 38.0, 43.0, 62.0, 72.0, 86.0, 121.0, 209.0, 89.0, 265.0]),\n",
              "       ...,\n",
              "       list([7.0, 11.0, 21.0, 23.0, 26.0, 36.0, 38.0, 43.0, 196.0, 351.0]),\n",
              "       list([7.0, 11.0, 21.0, 23.0, 26.0, 36.0, 38.0, 43.0, 63.0, 72.0, 100.0, 170.0, 352.0]),\n",
              "       list([11.0, 21.0, 23.0, 26.0, 36.0, 38.0, 43.0, 63.0, 72.0, 131.0, 352.0])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ph3gOXp3dB",
        "colab_type": "text"
      },
      "source": [
        "### Pad to (maxvisit,maxlen) matrices for each trajectory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGMlOqPVl0iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = keras.preprocessing.sequence.pad_sequences(clean, maxlen=maxlen)\n",
        "ID2_temp = data['ID2'].to_numpy().reshape((data.shape[0],1))\n",
        "X = np.concatenate((ID2_temp,X),axis=1)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu_NTnJrmLX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnVfMKxmt-b1",
        "colab_type": "text"
      },
      "source": [
        "## Split train/val/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM2hHrCMuC7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-01u5urrvVD9"
      },
      "source": [
        "# Embedding\n",
        "Two seperate embedding layers, one for tokens, one for token index (positions).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YThp4e7dvVD9",
        "colab": {}
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, emded_dim, name=None):\n",
        "        super(TokenAndPositionEmbedding, self).__init__(name=name)\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=emded_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q-5MlfYZvVD2"
      },
      "source": [
        "# Multi head self attention\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UYH9FtFdvVD3",
        "colab": {}
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0WQBQYvVD5"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGC4anJ4vVD6",
        "colab": {}
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate, name=None):\n",
        "        super(TransformerBlock, self).__init__(name=name)\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xm-Frk_BvVED"
      },
      "source": [
        "# Model\n",
        "\n",
        "Transformer layer outputs one vector for each time step of our input sequence.\n",
        "Here, we take the mean across all time steps and\n",
        "use a feed forward network on top of it to classify text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOH1CeHTvVED",
        "colab": {}
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "dense_units = 20\n",
        "dropout_rate = 0.1\n",
        "vocab_size=1000\n",
        "\n",
        "visit_input = layers.Input(shape=(maxlen,), name='visit_input') \n",
        "# I/O(batch, max_vars)\n",
        "\n",
        "visit_embedding = TokenAndPositionEmbedding(maxlen=maxlen, vocab_size=vocab_size, \n",
        "                                            emded_dim=embed_dim, name='visit_embedding')(visit_input) \n",
        "# O(batch, max_vars, embed_dim)\n",
        " \n",
        "transformer = TransformerBlock(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, \n",
        "                               dropout_rate=dropout_rate, name='transformer')(visit_embedding)\n",
        "# O(batch, max_vars, embed_dim)\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(transformer) # ...\n",
        "# O(batch, embed_dim)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "# O(batch, embed_dim)\n",
        "x = layers.Dense(dense_units, activation=\"relu\")(x) # nonlinear activation\n",
        "# O(batch, dense_units)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "# O(batch, dense_units)\n",
        "\n",
        "\n",
        "#outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "visit_output = layers.Dense(1, activation=\"sigmoid\", name='visit_output')(x)\n",
        "# O(batch, 1)\n",
        "\n",
        "model = keras.Model(inputs=visit_input, outputs=visit_output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZ2grHBLvVEI"
      },
      "source": [
        "# Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJQ-AViBvVEJ",
        "colab": {}
      },
      "source": [
        "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc',patience=1,min_delta=.001),\n",
        "                  keras.callbacks.ModelCheckpoint(filepath='my_model.h5',monitor='val_loss',save_best_only=True)]\n",
        "\n",
        "\n",
        "#model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=5,\n",
        "                    #callbacks=callbacks_list,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}